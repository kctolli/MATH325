---
title: "Table of Contents"
---

<!-- You can delete the following copyright statement if you wish: -->

<div style="color:gray;"><!-- Code to change the following paragraphs to gray -->

This page, and all pages of this notebook, are meant to be customized to become a useful *Guide to Statistical Analysis* in R for your *current* and *future* self.


<!-- <div style="font-size:.8em;"><!-- Code to shrink font-size of following paragraph --> 

<!-- To begin customizing, [download](https://github.com/saundersg/Statistics-Notebook) your own copy of the book <span style="font-size:.8em;">(if you haven't already)</span>. Please note the [GNU General Public License](https://choosealicense.com/licenses/gpl-3.0/) when downloading. You are free to delete this commentary in your own copy of the notebook. -->

<!-- </div><!-- Ends smaller font-size section -->

</div> <!-- End gray text section -->

<!-- <!-- End of download and copyright instructions. --> 


<!-- This is how to comment text out. You can comment out the above instructions if you wish. Comments allow the text to remain in the Rmd file, but not be displayed in the html file. -->

## {.tabset .tabset-fade}

### Hide 

### Show Notes {.tabset .tabset-fade}

<!-- This is a great place to add general notes --------------- -->

**This comes from the [*Making Inference*](./MakingInference.html) page of this book**

It is common to only have a sample of data from some population of interest. Using the information from the sample to reach conclusions about the population is called making inference. When statistical inference is performed properly, the conclusions about the population are almost always correct.

#### Hypothesis Testing

One of the great focal points of statistics concerns hypothesis testing. Science generally agrees upon the principle that truth must be uncovered by the process of elimination. The process begins by establishing a starting assumption, or null hypothesis (H0). Data is then collected and the evidence against the null hypothesis is measured, typically with the p-value. The p-value becomes small (gets close to zero) when the evidence is extremely different from what would be expected if the null hypothesis were true. When the p-value is below the significance level α (typically α=0.05) the null hypothesis is abandoned (rejected) in favor of a competing alternative hypothesis (Ha).

#### Managing Decision Errors

When the p-value approaches zero, one of two things must be occurring. Either an extremely rare event has happened or the null hypothesis is incorrect. Since the second option, that the null hypothesis is incorrect, is the more plausible option, we reject the null hypothesis in favor of the alternative whenever the p-value is close to zero. It is important to remember that rejecting the null hypothesis could however be a mistake.

* Type I Error (Significance Level, Confidence and α)
  - Defined as rejecting the null hypothesis when it is actually true
  - A hypothesis test controls the probability of a Type I Error
  - The typical value of α is 0.05
  - Defined as 1−α or the opposite of a Type I error
* Type II Errors (β, and Power)
  - Defined as failing to reject the null hypothesis when it is actually false
  - The typical value of β often unknown

##### Sufficient Evidence

Statistics comes in to play with hypothesis testing by defining the phrase “sufficient evidence.” When there is “sufficient evidence” in the data, the null hypothesis is rejected and the alternative hypothesis becomes the working hypothesis.

There are many statistical approaches to this problem of measuring the significance of evidence, but in almost all cases, the final measurement of evidence is given by the p-value of the hypothesis test. The p-value of a test is defined as the probability of the evidence being as extreme or more extreme than what was observed assuming the null hypothesis is true. This is an interesting phrase that is at first difficult to understand.

The “as extreme or more extreme” part of the definition of the p-value comes from the idea that the null hypothesis will be rejected when the evidence in the data is extremely inconsistent with the null hypothesis. If the data is not extremely different from what we would expect under the null hypothesis, then we will continue to believe the null hypothesis. Although, it is worth emphasizing that this does not prove the null hypothesis to be true.

##### Evidence not Proof

Hypothesis testing allows us a formal way to decide if we should “conclude the alternative” or “continue to accept the null.” It is important to remember that statistics (and science) cannot prove anything, just show evidence towards. Thus we never really prove a hypothesis is true, we simply show evidence towards or against a hypothesis.

#### Calculating the p-Value

Recall that the p-value measures how extremely the data (the evidence) differs from what is expected under the null hypothesis. Small p-values lead us to discard (reject) the null hypothesis.The P-value is the probability of obtaining a result (called a test statistic) at least as extreme as the one you calculated, assuming the null hypothesis is true. 

A p-value can be calculated whenever we have two things.

* A test statistic, which is a way of measuring how “far” the observed data is from what is expected under the null hypothesis.
* The sampling distribution of the test statistic, which is the theoretical distribution of the test statistic over all possible samples, assuming the null hypothesis was true. 

A distribution describes how data is spread out. When we know the shape of a distribution, we know which values are possible, but more importantly which values are most plausible (likely) and which are the least plausible (unlikely). The p-value uses the sampling distribution of the test statistic to measure the probability of the observed test statistic being as extreme or more extreme than the one observed.

All p-value computation methods can be classified into two broad categories, parametric methods and nonparametric methods.

#### Parametric Methods

Parametric methods assume that, under the null hypothesis, the test statistic follows a specific theoretical parametric distribution. Parametric methods are typically more statistically powerful than nonparametric methods, but necessarily force more assumptions on the data.

Parametric distributions are theoretical distributions that can be described by a mathematical function. There are many theoretical distributions. 

Four of the most widely used parametric distributions are:

* Normal Distribution 
  - It is a theoretical distribution that approximates the distributions of many real life data distributions
* Chi Squared Distribution 
  - It only allows for values that are greater than or equal to zero
  - It has a few real life applications, by far its greatest use is theoretical
* t Distribution
  - A close friend of the normal distribution
  - It is used extensively in hypothesis testing
* F Distribution  
  - It is the ratio of two chi squared random variables that are each divided by their respective degrees of freedom
  
##### Parametric Tests

* [t Tests](./tTests.html)
* [ANOVA Tests](./ANOVA.html)
* [Chi-squared Tests](./ChiSquaredTests.html)

#### Nonparametric Methods

Nonparametric methods place minimal assumptions on the distribution of data. They allow the data to “speak for itself.” They are typically less powerful than the parametric alternatives, but are more broadly applicable because fewer assumptions need to be satisfied. 

##### Nonparametric Tests

* [Wilcoxon Tests](./WilcoxonTests.html)
* [Kruskal-Wallis Tests](./Kruskal.html)
* [Permutation Tests](./PermutationTests.html)

<!-- End your notes before here. ------------------------------------- -->
##

----

<div style="float:left;width:125px;" align=center class="tooltipimage">
<img src="./Images/QuantY.png" width=35px;>
  <span class="tooltipimagetext">Y is a single quantitative variable of interest. This would be like "heights" of BYU-Idaho students.</span>
</div>

## One Quantitative Response Variable Y {.tabset .tabset-pills}

### Data Summaries
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

#### Numerical 

<!-- [Mean, median, five-number summary, standard deviation](NumericalSummaries.html) -->

* Mean (average) - Center of Mass - `mean(object)`
* Median - Middle Data Point - `median(object)`
* Quartiles (five-number summary) - Spread of Data - `quantile(object, percentile)` 
* Standard Deviation - Measures how spread out the data are from the mean - `sd(object)`

<br/>

--- *Use `summary(object)`*

  - Gives the five number summary 
    + Min
    + 1st Quartile
    + Median 
    + Mean
    + 3rd Quartile
    + Max

#### Graphics

<a href="GraphicalSummaries.html#histogram">
  <img class="myhover" src="./Images/histogram.png" alt="Histogram" title="Histogram">
</a>
<a href="GraphicalSummaries.html#dot-plots">
  <img class="myhover" src="./Images/dotplotsingle.png" alt="Dot Plot" title="Dot Plot">
</a>
<a href="GraphicalSummaries.html#boxplots">
  <img class="myhover" src="./Images/boxplotsingle.png" alt="Boxplot" title="Boxplot">
</a>



<!--- End your notes before here.  ------------------>
</div>

### Tests
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

<!-- Add your own notes about appropriate inferential procedures for this type of data here. -->


* T-tests 
  + One Sample `t.test(NameOfYourData$Y, mu = YourNull, alternative = YourAlternative, conf.level = 0.95`
  + Paired Sample `t.test(NameOfYourData$Y1, NameOfYourData$Y2, paired = TRUE, mu = YourNull, alternative = YourAlternative, conf.level = 0.95)`
* Wilcoxon Tests 
  + Signed-Rank `wilcox.test(object1, object2, mu = YourNull, alternative = YourAlternative, paired = TRUE, conf.level = 0.95)`




<!--- End of Add content area.  ------------------>
</div>

#
<div style="clear:both;"></div>

----

<div style="float:left;width:125px;" align=center class="tooltipimage">
<img src="./Images/QuantYQualXg2.png" width=59px;>
  <span class="tooltipimagetext">Y is a single quantitative variable of interest. This would be like "heights" of BYU-Idaho students. X is a qualitative (categorical) variable of interest like "gender" that has just two groups "A" and "B". So this logo represents situtations where we would want to compare heights of male (group A) and female (group B) students.</span>
</div>

## Quantitative Y | Categorical X (2 Groups) {.tabset .tabset-pills}

### Data Summaries
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->


#### Numerical 

* Mean (average) - Center of Mass - `mean(object)`
* Median - Middle Data Point - `median(object)`
* Quartiles (five-number summary) - Spread of Data - `quantile(object, percentile)` or `summary(object)`
* Standard Deviation - Measures how spread out the data are from the mean - `sd(object)`
* n - Sample size - `n()`

<br/>

--- *Use group_by(columnGroupsName)*

  - columnGroupsName = Categorical X
  - Function from tidyverse package
  - Normal used with the summarise or mutate
    + Qualitative in Group By
    + Quantitative in Summarize
    
#### Graphics


<a href="GraphicalSummaries.html#boxplots">
  <img class="myhover" src="./Images/boxplot.png" alt="Side-by-side Boxplots" title="Side-by-side Boxplots">
</a>
<a href="GraphicalSummaries.html#dot-plots">
  <img class="myhover" src="./Images/dotplotdouble.png" alt="Dot Plot" title="Side-by-side Dot Plots">
</a>



<!--- End of Add content area.  ------------------>
</div>

### Tests
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

<!-- Add your own notes about appropriate inferential procedures for this type of data here. -->


* T-tests 
  + Independent `t.test(Y ~ X, data = YourData, mu = YourNull, alternative = YourAlternative, conf.level = 0.95)`
* Wilcoxon 
  + Rank Sum (Mann-Whitney) `wilcox.test(Y ~ X, data = YourData, mu = YourNull, alternative = YourAlternative, conf.level = 0.95)`


<!--- End of Add content area.  ------------------>
</div>

##
<div style="clear:both;"></div>

----

<div style="float:left;width:125px;" align=center class="tooltipimage">
<img src="./Images/QuantYQualXg3plus.png" width=59px;>
  <span class="tooltipimagetext">Y is a single quantitative variable of interest, like "heights" of BYU-Idaho students. X is a categorical (qualitative) variable like which Math 221 you took, 221A, 221B, or 221C. In other words, X has three or more groups. So "Classrank" could be X, with groups "Freshman", "Sophomore", "Junior", and "Senior".</span>
</div>

## Quantitative Y | Categorical X (3+ Groups) {.tabset .tabset-pills}

### Data Summaries
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

#### Numerical 

* Minimum - Smallest occurring data value - `min(object)`
* Maximum - Largest occurring data value - `max(object)`
* Mean (average) - Center of Mass - `mean(object)`
* Median - Middle Data Point - `median(object)`
* Quartiles (five-number summary) - Spread of Data - `quantile(object, percentile)` or `summary(object)`
* Standard Deviation - Measures how spread out the data are from the mean - `sd(object)`
* n - Sample size - `n()`

<br/>

--- *Use `favstats(x ~ g, data=YourDataSet)`*

  - x is a numeric vector of data values that represents the quantatitive response variable.
  - g is a qualitative grouping variable defining which groups each value in x belongs to. 
  - YourDataSet is the name of your data set.

#### Graphics



<a href="GraphicalSummaries.html#boxplots">
  <img class="myhover" src="./Images/boxplotthree.png" alt="Side-by-side Boxplots" title="Side-by-side Boxplots 3+ Groups">
</a>
<a href="GraphicalSummaries.html#dot-plots">
  <img class="myhover" src="./Images/dotplottriple.png" alt="Side-by-side Dot Plots" title="Side-by-side Dot Plots 3+ Groups">
</a>

<!--- End of Add content area.  ------------------>
</div>

### Tests
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

* ANOVA
  + One-way `aov(y ~ A, data=YourDataSet)`
  + Two-way `aov(y ~ A+B+A:B, data=YourDataSet)`
  + Block Design `aov(y ~ Block+A+B+A:B, data=YourDataSet)`
* Kruskal-Wallis 
  + Rank Sum `kruskal.test(x ~ g, data=YourDataSet)`




<!--- End of Add content area.  ------------------>
</div>

#
<div style="clear:both;"></div>

----

<div style="float:left;width:125px;" align=center class="tooltipimage">
<img src="./Images/QuantYQuantX.png" width=59px;>
  <span class="tooltipimagetext">Y is a single quantitative variable of interest, like "height". X is another single quantitative variable of interest, like "shoe-size". This would imply we are using "shoe-size" (X) to explain "height" (Y).</span>
</div>

## Quantitative Y | Quantitative X {.tabset .tabset-pills}

### Data Summaries
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->



#### Numerical 



#### Graphics






<a href="GraphicalSummaries.html#scatterplots">
  <img class="myhover" src="./Images/scatterplot.png" alt="Scatterplot" title="Scatterplot">
</a>

<!--- End of Add content area.  ------------------>
</div>

### Tests
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

* Simple Linear Regression `lm(Y ~ X, data = YourDataSet)`





<!--- End of Add content area.  ------------------>
</div>

#
<div style="clear:both;"></div>

----

<div style="float:left;width:125px;" align=center class="tooltipimage">
<img src="./Images/QuantYMultX.png" width=100px;>
  <span class="tooltipimagetext">Y is a single quantitative variable of interest, like height. While we could use an X1 of "shoe-size" to explain height, we might also want to use a second x-variable, X2, like "gender" to help explain height. Further x-variables could also be used.</span>
</div>

## Quantitative Y | Multiple X {.tabset .tabset-pills}

### Data Summaries
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

 



#### Numerical 



#### Graphics





<a href="GraphicalSummaries.html#scatterplots">
  <img class="myhover" src="./Images/scatterplotmany.png" alt="Scatterplot" title="Scatterplot with Color and Sizing">
</a>

<!--- End of Add content area.  ------------------>
</div>

### Tests
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

* Multiple Linear Regression `lm(Y ~ X1 + X2 + X1:X2 + ..., data = YourDataSet)`





<!--- End of Add content area.  ------------------>
</div>

#
<div style="clear:both;"></div>

----

<div style="float:left;width:125px;" align=center class="tooltipimage">
<img src="./Images/BinomYQuantX.png" width=59px;>
  <span class="tooltipimagetext">Y is a single categorical (qualitative) variable of interest where 1 (success) or 0 (failure) are the only possible values for Y. This would be like "getting an A in Math 325" where 1 means you got an A and 0 means you didn't. We might use an explanatory variable X of "height" to see if taller students are more likely to get an A in Math 325 than shorter students. (They aren't, if you were wondering.)</span>
</div>

## Binomial Y | Quantitative X {.tabset .tabset-pills}

### Data Summaries
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

 

#### Numerical 




#### Graphics





<a href="GraphicalSummaries.html#scatterplots">
  <img class="myhover" src="./Images/scatterplotbinomY.png" alt="Scatterplot with Binomial Y" title="Scatterplot with Binomial Y">
</a>

<!--- End of Add content area.  ------------------>
</div>

### Tests
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

* Simple Logistic Regression Model `glm(Y ~ X, data = YourDataSet, family = binomial)`






<!--- End of Add content area.  ------------------>
</div>

#
<div style="clear:both;"></div>

----

<div style="float:left;width:125px;" align=center class="tooltipimage">
<img src="./Images/BinomYMultX.png" width=100px;>
  <span class="tooltipimagetext">Y is a single categorical (qualitative) variable of interest where 1 (success) or 0 (failure) are the only possible values for Y. This would be like "getting an A in Math 325" where 1 means you got an A and 0 means you didn't. We might use an explanatory variable X1 of "height" and a second explanatory variable X2 of "gender" to try to predict whether or not a student will get an A in Math 325.</span>
</div>

## Binomial Y | Multiple X {.tabset .tabset-pills}

### Data Summaries
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

 

#### Numerical 



#### Graphics





<a href="GraphicalSummaries.html#scatterplots">
  <img class="myhover" src="./Images/scatterplotbinomYmult.png" alt="Scatterplot with Binomial Y" title="Scatterplot with Binomial Y, including coloring and shading">
</a>

<!--- End of Add content area.  ------------------>
</div>

### Tests
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

* Mutiple Logistic Regression Model `glm(Y ~ X1 * X2 * ... , data = YourDataSet, family = binomial)`






<!--- End of Add content area.  ------------------>
</div>

#
<div style="clear:both;"></div>

----

<div style="float:left;width:125px;" align=center class="tooltipimage">
<img src="./Images/QualYQualX.png" width=59px;>
  <span class="tooltipimagetext">Y is a single categorical variable of interest, like gender. X is another categorical variable of interest, like "hair color". This type of data would help us understand if men or women are more likely to have certain hair colors than the other gender.</span>
</div>

## Categorical Y | Categorical X {.tabset .tabset-pills}

### Data Summaries
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

 

#### Numerical 



#### Graphics




<a href="GraphicalSummaries.html#bar-charts">
  <img class="myhover" src="./Images/barplot.png" alt="Bar Chart" title="Bar Chart">
</a>

<!--- End of Add content area.  ------------------>
</div>

### Tests
<div style="padding-left:125px;color:gray;">
<!-- Add your customizations in the area below: -->

* Chi-squared Test of Independence 
  + `chisq.test(x)` 
  + `chisq.test(table(Dataset$variable, Dataset$variable))`
* Nonparametric Chi-squared Test `chisq.test(x, simulate.p.value=TRUE)`



<!--- End of Add content area.  ------------------>
</div>

#
<div style="clear:both;"></div>

----

<footer> &nbsp; &nbsp; "Education is not the learning of facts it's rather the training of the mind to think" --- Albert Eistein</footer>

